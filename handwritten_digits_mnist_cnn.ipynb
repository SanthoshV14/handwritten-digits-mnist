{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10XWl3TzPcy0"
      },
      "source": [
        "*Downloading the dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G_0kYwxDh38"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Importing the dataset\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "# The training data will have 60000 samples, reshape for necessary array dimensions\n",
        "train_X = train_X.astype('float32')\n",
        "train_X /= 255\n",
        "train_X, valid_X = train_X[:55000], train_X[55000:]\n",
        "# Create desired out or one-hot-array. Range [0, 9] with vector size 10\n",
        "train_y = np_utils.to_categorical(train_y)\n",
        "train_y, valid_y = train_y[:55000], train_y[55000:]\n",
        "# Test data contains 10000 samples\n",
        "test_X = test_X.reshape(test_X.shape[0], 1, 28*28)\n",
        "test_X = test_X.astype('float32')\n",
        "test_X /= 255\n",
        "test_y = np_utils.to_categorical(test_y)\n",
        "#%%\n",
        "\n",
        "def plot_digits(instances, images_per_row=10, **options):\n",
        "  size = 28\n",
        "  images_per_row = min(len(instances), images_per_row)\n",
        "  images = [instance.reshape(size,size) for instance in instances]\n",
        "  n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "  row_images = []\n",
        "  n_empty = n_rows * images_per_row - len(instances)\n",
        "  images.append(np.zeros((size, size * n_empty)))\n",
        "  for row in range(n_rows):\n",
        "    rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
        "    row_images.append(np.concatenate(rimages, axis=1))\n",
        "    image = np.concatenate(row_images, axis=0)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
        "    plt.axis(\"off\")\n",
        "#%%\n",
        "plt.figure(figsize=(9,9))\n",
        "example_images = train_X[100:200]\n",
        "plot_digits(example_images, images_per_row=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XO9aKGbPr98"
      },
      "source": [
        "*Model creation - with less than 100K learnable params*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbTU4SB8PQtx"
      },
      "outputs": [],
      "source": [
        "# Model creation\n",
        "from keras import models, layers\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(5, 2, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(5, 2, activation=\"relu\", padding=\"same\"),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_X, train_y, epochs=30, validation_data=(valid_X, valid_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8IJgVnP789"
      },
      "source": [
        "*Plotting the accuracies*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2EsjZjkPWaj"
      },
      "outputs": [],
      "source": [
        "# Plotting the accuracies\n",
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxRBHrdIQFYz"
      },
      "source": [
        "*Evaluating the Unseen data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWBRMv1uPY7y"
      },
      "outputs": [],
      "source": [
        "# Evaluating the Unseen data\n",
        "model.evaluate(test_X, test_y)\n",
        "\n",
        "y_prob = model.predict(test_X)\n",
        "y_prob = y_prob.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhU2ergWQIK6"
      },
      "source": [
        "*Saving the model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubr3dc1V9MBO",
        "outputId": "f96330cc-a99d-42b2-bd92-2a9011ab0059"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# Saving the model\n",
        "model.save('./')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
